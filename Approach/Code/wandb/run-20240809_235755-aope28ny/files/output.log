
Max Decision Length:  35199
/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
You are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
[34m[1mwandb[39m[22m: [33mWARNING[39m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                     | 0/14740 [00:00<?, ?it/s]/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|                                                                                          | 1/14740 [00:08<34:21:53,  8.39s/it]
{'loss': 3.3566, 'grad_norm': 38.07674789428711, 'learning_rate': 4.99966078697422e-05, 'epoch': 0.0}
{'loss': 1.8147, 'grad_norm': 29.59360694885254, 'learning_rate': 4.9993215739484404e-05, 'epoch': 0.0}

  0%|                                                                                           | 6/14740 [00:10<3:51:53,  1.06it/s]
{'loss': 0.9182, 'grad_norm': 3.0622143745422363, 'learning_rate': 4.998643147896879e-05, 'epoch': 0.01}
{'loss': 0.2555, 'grad_norm': 2.4208567142486572, 'learning_rate': 4.998303934871099e-05, 'epoch': 0.01}
{'loss': 2.0088, 'grad_norm': 3.3620615005493164, 'learning_rate': 4.997964721845319e-05, 'epoch': 0.01}

  0%|                                                                                          | 10/14740 [00:12<2:27:11,  1.67it/s]
{'loss': 1.026, 'grad_norm': 0.8596434593200684, 'learning_rate': 4.997286295793759e-05, 'epoch': 0.01}
{'loss': 0.7127, 'grad_norm': 0.7765845060348511, 'learning_rate': 4.996947082767979e-05, 'epoch': 0.01}
{'loss': 0.6674, 'grad_norm': 1.0383098125457764, 'learning_rate': 4.996607869742198e-05, 'epoch': 0.01}

  0%|                                                                                          | 12/14740 [00:14<2:56:03,  1.39it/s]
{'loss': 0.2755, 'grad_norm': 0.42117074131965637, 'learning_rate': 4.9959294436906375e-05, 'epoch': 0.02}
{'loss': 1.0396, 'grad_norm': 1.125282645225525, 'learning_rate': 4.995590230664858e-05, 'epoch': 0.02}

  0%|                                                                                          | 16/14740 [00:16<2:14:10,  1.83it/s]
{'loss': 1.5547, 'grad_norm': 1.3609400987625122, 'learning_rate': 4.9949118046132974e-05, 'epoch': 0.02}
{'loss': 1.1226, 'grad_norm': 0.9534592628479004, 'learning_rate': 4.994572591587518e-05, 'epoch': 0.02}
{'loss': 1.2353, 'grad_norm': 0.9204946756362915, 'learning_rate': 4.994233378561737e-05, 'epoch': 0.02}

  0%|▏                                                                                         | 21/14740 [00:18<2:03:38,  1.98it/s]
{'loss': 1.1025, 'grad_norm': 1.2739557027816772, 'learning_rate': 4.993554952510176e-05, 'epoch': 0.03}
{'loss': 1.5395, 'grad_norm': 1.3556026220321655, 'learning_rate': 4.9932157394843966e-05, 'epoch': 0.03}
{'loss': 0.7972, 'grad_norm': 0.8333075046539307, 'learning_rate': 4.9928765264586164e-05, 'epoch': 0.03}

  0%|▏                                                                                         | 25/14740 [00:20<2:02:23,  2.00it/s]
{'loss': 0.2565, 'grad_norm': 0.36740896105766296, 'learning_rate': 4.992198100407056e-05, 'epoch': 0.03}
{'loss': 0.7492, 'grad_norm': 0.8606246709823608, 'learning_rate': 4.9918588873812755e-05, 'epoch': 0.03}

  0%|▏                                                                                         | 28/14740 [00:22<2:17:26,  1.78it/s]
{'loss': 0.5209, 'grad_norm': 0.524712324142456, 'learning_rate': 4.9911804613297156e-05, 'epoch': 0.04}
{'loss': 1.1909, 'grad_norm': 0.8219888210296631, 'learning_rate': 4.9908412483039353e-05, 'epoch': 0.04}
{'loss': 0.5902, 'grad_norm': 0.5829033851623535, 'learning_rate': 4.990502035278155e-05, 'epoch': 0.04}

  0%|▏                                                                                         | 32/14740 [00:24<2:06:56,  1.93it/s]
{'loss': 0.6744, 'grad_norm': 0.8594589233398438, 'learning_rate': 4.9898236092265945e-05, 'epoch': 0.04}
{'loss': 0.452, 'grad_norm': 0.36245250701904297, 'learning_rate': 4.989484396200814e-05, 'epoch': 0.04}
{'loss': 0.5907, 'grad_norm': 0.4312320649623871, 'learning_rate': 4.989145183175034e-05, 'epoch': 0.04}

  0%|▏                                                                                         | 36/14740 [00:26<2:03:49,  1.98it/s]
{'loss': 1.651, 'grad_norm': 1.0667479038238525, 'learning_rate': 4.988466757123474e-05, 'epoch': 0.05}
{'loss': 1.1215, 'grad_norm': 0.9183390140533447, 'learning_rate': 4.988127544097694e-05, 'epoch': 0.05}
{'loss': 1.3672, 'grad_norm': 0.8694302439689636, 'learning_rate': 4.987788331071913e-05, 'epoch': 0.05}

  0%|▏                                                                                         | 39/14740 [00:28<2:24:33,  1.69it/s]
{'loss': 1.2044, 'grad_norm': 0.7268335223197937, 'learning_rate': 4.987109905020353e-05, 'epoch': 0.05}
{'loss': 1.5338, 'grad_norm': 0.7883985042572021, 'learning_rate': 4.9867706919945726e-05, 'epoch': 0.05}
{'loss': 0.4705, 'grad_norm': 0.3412701189517975, 'learning_rate': 4.986431478968793e-05, 'epoch': 0.05}

  0%|▎                                                                                         | 43/14740 [00:30<2:07:42,  1.92it/s]
{'loss': 0.1927, 'grad_norm': 0.2643704414367676, 'learning_rate': 4.9857530529172325e-05, 'epoch': 0.06}
{'loss': 0.8929, 'grad_norm': 0.6459002494812012, 'learning_rate': 4.9854138398914515e-05, 'epoch': 0.06}
{'loss': 1.0409, 'grad_norm': 0.6563420295715332, 'learning_rate': 4.985074626865672e-05, 'epoch': 0.06}

  0%|▎                                                                                         | 47/14740 [00:32<2:04:41,  1.96it/s]
{'loss': 0.8468, 'grad_norm': 0.7719841003417969, 'learning_rate': 4.9843962008141113e-05, 'epoch': 0.06}
{'loss': 0.9695, 'grad_norm': 0.7208526134490967, 'learning_rate': 4.984056987788332e-05, 'epoch': 0.06}
{'loss': 0.808, 'grad_norm': 0.5792112350463867, 'learning_rate': 4.9837177747625515e-05, 'epoch': 0.07}

  0%|▎                                                                                         | 51/14740 [00:34<2:02:58,  1.99it/s]
{'loss': 0.4796, 'grad_norm': 0.32652002573013306, 'learning_rate': 4.98303934871099e-05, 'epoch': 0.07}
{'loss': 0.4223, 'grad_norm': 0.49966317415237427, 'learning_rate': 4.9827001356852106e-05, 'epoch': 0.07}

  0%|▎                                                                                         | 55/14740 [00:36<2:11:38,  1.86it/s]
{'loss': 1.1887, 'grad_norm': 1.5852620601654053, 'learning_rate': 4.98202170963365e-05, 'epoch': 0.07}
{'loss': 1.2682, 'grad_norm': 0.8229203224182129, 'learning_rate': 4.9816824966078704e-05, 'epoch': 0.07}
{'loss': 0.6912, 'grad_norm': 0.5928487181663513, 'learning_rate': 4.98134328358209e-05, 'epoch': 0.07}

  0%|▎                                                                                         | 59/14740 [00:38<2:05:12,  1.95it/s]
{'loss': 1.8795, 'grad_norm': 0.8567817807197571, 'learning_rate': 4.980664857530529e-05, 'epoch': 0.08}
{'loss': 0.9082, 'grad_norm': 0.7151505947113037, 'learning_rate': 4.980325644504749e-05, 'epoch': 0.08}
{'loss': 0.8856, 'grad_norm': 0.6853234171867371, 'learning_rate': 4.979986431478969e-05, 'epoch': 0.08}

  0%|▍                                                                                         | 63/14740 [00:40<2:02:53,  1.99it/s]
{'loss': 1.1531, 'grad_norm': 0.6440544724464417, 'learning_rate': 4.979308005427409e-05, 'epoch': 0.08}
{'loss': 0.1745, 'grad_norm': 0.28385937213897705, 'learning_rate': 4.978968792401629e-05, 'epoch': 0.08}

  0%|▍                                                                                         | 66/14740 [00:42<2:15:18,  1.81it/s]
{'loss': 0.2438, 'grad_norm': 0.3585584759712219, 'learning_rate': 4.9782903663500676e-05, 'epoch': 0.09}
{'loss': 1.2214, 'grad_norm': 0.7163496613502502, 'learning_rate': 4.977951153324288e-05, 'epoch': 0.09}
{'loss': 0.9138, 'grad_norm': 0.9383996725082397, 'learning_rate': 4.977611940298508e-05, 'epoch': 0.09}

  0%|▍                                                                                         | 70/14740 [00:44<2:05:27,  1.95it/s]
{'loss': 0.7866, 'grad_norm': 0.6496995687484741, 'learning_rate': 4.976933514246948e-05, 'epoch': 0.09}
{'loss': 0.6667, 'grad_norm': 0.9586228132247925, 'learning_rate': 4.976594301221167e-05, 'epoch': 0.09}
{'loss': 1.5535, 'grad_norm': 0.813542902469635, 'learning_rate': 4.9762550881953866e-05, 'epoch': 0.09}

  1%|▍                                                                                         | 74/14740 [00:46<2:04:18,  1.97it/s]
{'loss': 2.0993, 'grad_norm': 7.752205848693848, 'learning_rate': 4.975576662143827e-05, 'epoch': 0.1}
{'loss': 0.7969, 'grad_norm': 0.9183576703071594, 'learning_rate': 4.9752374491180464e-05, 'epoch': 0.1}
{'loss': 0.9567, 'grad_norm': 0.7020216584205627, 'learning_rate': 4.974898236092266e-05, 'epoch': 0.1}

  1%|▍                                                                                         | 77/14740 [00:48<2:03:28,  1.98it/s]
{'loss': 1.6707, 'grad_norm': 1.1083431243896484, 'learning_rate': 4.9742198100407056e-05, 'epoch': 0.1}
{'loss': 1.0114, 'grad_norm': 0.7281258702278137, 'learning_rate': 4.973880597014925e-05, 'epoch': 0.1}
{'loss': 0.9076, 'grad_norm': 0.9037003517150879, 'learning_rate': 4.973541383989146e-05, 'epoch': 0.11}

  1%|▍                                                                                         | 81/14740 [00:50<2:11:21,  1.86it/s]
{'loss': 1.8075, 'grad_norm': 1.6099683046340942, 'learning_rate': 4.972862957937585e-05, 'epoch': 0.11}
{'loss': 0.2451, 'grad_norm': 0.5598034262657166, 'learning_rate': 4.972523744911805e-05, 'epoch': 0.11}

  1%|▌                                                                                         | 85/14740 [00:52<2:04:49,  1.96it/s]
{'loss': 1.7425, 'grad_norm': 0.8403222560882568, 'learning_rate': 4.971845318860244e-05, 'epoch': 0.11}
{'loss': 0.6286, 'grad_norm': 0.5998779535293579, 'learning_rate': 4.971506105834464e-05, 'epoch': 0.11}
{'loss': 0.4142, 'grad_norm': 0.366377592086792, 'learning_rate': 4.9711668928086844e-05, 'epoch': 0.12}

  1%|▌                                                                                         | 89/14740 [00:54<2:05:39,  1.94it/s]
{'loss': 0.4208, 'grad_norm': 0.427077054977417, 'learning_rate': 4.970488466757124e-05, 'epoch': 0.12}
{'loss': 1.2959, 'grad_norm': 0.9221994280815125, 'learning_rate': 4.9701492537313436e-05, 'epoch': 0.12}
{'loss': 0.9787, 'grad_norm': 0.6440848708152771, 'learning_rate': 4.969810040705563e-05, 'epoch': 0.12}

  1%|▌                                                                                         | 92/14740 [00:56<2:25:42,  1.68it/s]
{'loss': 0.9471, 'grad_norm': 0.643416166305542, 'learning_rate': 4.969131614654003e-05, 'epoch': 0.12}
{'loss': 1.0727, 'grad_norm': 0.8883627653121948, 'learning_rate': 4.968792401628223e-05, 'epoch': 0.12}

  1%|▌                                                                                         | 96/14740 [00:58<2:09:51,  1.88it/s]
{'loss': 0.6473, 'grad_norm': 0.6495242118835449, 'learning_rate': 4.9681139755766626e-05, 'epoch': 0.13}
{'loss': 0.9331, 'grad_norm': 0.7169466018676758, 'learning_rate': 4.9677747625508816e-05, 'epoch': 0.13}
{'loss': 0.248, 'grad_norm': 0.28581130504608154, 'learning_rate': 4.967435549525102e-05, 'epoch': 0.13}

  1%|▌                                                                                        | 100/14740 [01:00<2:06:26,  1.93it/s]
{'loss': 0.2077, 'grad_norm': 0.32592713832855225, 'learning_rate': 4.9667571234735414e-05, 'epoch': 0.13}
{'loss': 1.2844, 'grad_norm': 0.987266480922699, 'learning_rate': 4.966417910447762e-05, 'epoch': 0.13}
{'loss': 0.0874, 'grad_norm': 0.14923323690891266, 'learning_rate': 4.9660786974219815e-05, 'epoch': 0.14}

  1%|▌                                                                                        | 103/14740 [01:02<2:04:41,  1.96it/s]
{'loss': 1.2238, 'grad_norm': 0.6556232571601868, 'learning_rate': 4.96540027137042e-05, 'epoch': 0.14}
{'loss': 0.2875, 'grad_norm': 0.3344961702823639, 'learning_rate': 4.965061058344641e-05, 'epoch': 0.14}

  1%|▋                                                                                        | 107/14740 [01:04<2:14:18,  1.82it/s]
{'loss': 2.0622, 'grad_norm': 1.3441904783248901, 'learning_rate': 4.96438263229308e-05, 'epoch': 0.14}
{'loss': 1.3268, 'grad_norm': 0.9455006718635559, 'learning_rate': 4.9640434192673005e-05, 'epoch': 0.14}
{'loss': 0.3098, 'grad_norm': 0.2977774739265442, 'learning_rate': 4.96370420624152e-05, 'epoch': 0.15}

  1%|▋                                                                                        | 111/14740 [01:06<2:05:49,  1.94it/s]
{'loss': 0.2719, 'grad_norm': 0.30359402298927307, 'learning_rate': 4.963025780189959e-05, 'epoch': 0.15}
{'loss': 0.9822, 'grad_norm': 0.8265476822853088, 'learning_rate': 4.9626865671641794e-05, 'epoch': 0.15}
{'loss': 1.9202, 'grad_norm': 1.1649372577667236, 'learning_rate': 4.962347354138399e-05, 'epoch': 0.15}

  1%|▋                                                                                        | 115/14740 [01:08<2:03:10,  1.98it/s]
{'loss': 1.2904, 'grad_norm': 0.8046201467514038, 'learning_rate': 4.961668928086839e-05, 'epoch': 0.15}
{'loss': 0.3599, 'grad_norm': 0.540905773639679, 'learning_rate': 4.961329715061059e-05, 'epoch': 0.15}
{'loss': 1.0589, 'grad_norm': 0.6474657654762268, 'learning_rate': 4.960990502035278e-05, 'epoch': 0.16}

  1%|▋                                                                                        | 118/14740 [01:10<2:14:17,  1.81it/s]
{'loss': 0.4334, 'grad_norm': 0.4258728325366974, 'learning_rate': 4.960312075983718e-05, 'epoch': 0.16}
{'loss': 0.6322, 'grad_norm': 0.48567190766334534, 'learning_rate': 4.959972862957938e-05, 'epoch': 0.16}
{'loss': 0.9972, 'grad_norm': 0.5500593185424805, 'learning_rate': 4.9596336499321575e-05, 'epoch': 0.16}

  1%|▋                                                                                        | 122/14740 [01:12<2:06:49,  1.92it/s]
{'loss': 0.5556, 'grad_norm': 0.4010813534259796, 'learning_rate': 4.9589552238805977e-05, 'epoch': 0.16}
{'loss': 0.2325, 'grad_norm': 0.3135513663291931, 'learning_rate': 4.958616010854817e-05, 'epoch': 0.17}
{'loss': 0.418, 'grad_norm': 0.29163089394569397, 'learning_rate': 4.958276797829037e-05, 'epoch': 0.17}

  1%|▊                                                                                        | 126/14740 [01:14<2:05:07,  1.95it/s]
{'loss': 0.143, 'grad_norm': 0.23638762533664703, 'learning_rate': 4.9575983717774765e-05, 'epoch': 0.17}
{'loss': 0.956, 'grad_norm': 0.7564921379089355, 'learning_rate': 4.957259158751696e-05, 'epoch': 0.17}
{'loss': 1.3554, 'grad_norm': 0.7171652317047119, 'learning_rate': 4.9569199457259166e-05, 'epoch': 0.17}

  1%|▊                                                                                        | 130/14740 [01:17<2:30:35,  1.62it/s]
{'loss': 1.6732, 'grad_norm': 1.035089373588562, 'learning_rate': 4.9562415196743554e-05, 'epoch': 0.18}
{'loss': 1.0511, 'grad_norm': 0.6091455817222595, 'learning_rate': 4.955902306648576e-05, 'epoch': 0.18}

  1%|▊                                                                                        | 134/14740 [01:19<2:08:20,  1.90it/s]
{'loss': 0.3939, 'grad_norm': 0.3382141888141632, 'learning_rate': 4.955223880597015e-05, 'epoch': 0.18}
{'loss': 0.9582, 'grad_norm': 0.9148088693618774, 'learning_rate': 4.954884667571235e-05, 'epoch': 0.18}
{'loss': 0.2904, 'grad_norm': 0.30975812673568726, 'learning_rate': 4.9545454545454553e-05, 'epoch': 0.18}

  1%|▊                                                                                        | 138/14740 [01:21<2:02:48,  1.98it/s]
{'loss': 0.3944, 'grad_norm': 0.42457064986228943, 'learning_rate': 4.953867028493894e-05, 'epoch': 0.18}
{'loss': 1.6134, 'grad_norm': 0.6878453493118286, 'learning_rate': 4.9535278154681145e-05, 'epoch': 0.19}
{'loss': 1.1012, 'grad_norm': 0.5701576471328735, 'learning_rate': 4.953188602442334e-05, 'epoch': 0.19}

  1%|▊                                                                                        | 142/14740 [01:23<2:02:05,  1.99it/s]
{'loss': 0.1999, 'grad_norm': 0.25981369614601135, 'learning_rate': 4.9525101763907737e-05, 'epoch': 0.19}
{'loss': 0.4408, 'grad_norm': 0.44188201427459717, 'learning_rate': 4.9521709633649934e-05, 'epoch': 0.19}

  1%|▉                                                                                        | 145/14740 [01:24<2:11:51,  1.84it/s]
{'loss': 1.5858, 'grad_norm': 1.0213032960891724, 'learning_rate': 4.951492537313433e-05, 'epoch': 0.19}
{'loss': 0.5523, 'grad_norm': 0.8324979543685913, 'learning_rate': 4.951153324287653e-05, 'epoch': 0.2}
{'loss': 0.9848, 'grad_norm': 0.6641163229942322, 'learning_rate': 4.950814111261873e-05, 'epoch': 0.2}

  1%|▉                                                                                        | 149/14740 [01:26<2:03:32,  1.97it/s]
{'loss': 1.1346, 'grad_norm': 0.6133428812026978, 'learning_rate': 4.9501356852103124e-05, 'epoch': 0.2}
{'loss': 1.3089, 'grad_norm': 0.6721463203430176, 'learning_rate': 4.949796472184532e-05, 'epoch': 0.2}
{'loss': 0.1646, 'grad_norm': 0.21787232160568237, 'learning_rate': 4.949457259158752e-05, 'epoch': 0.2}

  1%|▉                                                                                        | 153/14740 [01:28<2:02:01,  1.99it/s]
{'loss': 0.8539, 'grad_norm': 0.7316873669624329, 'learning_rate': 4.948778833107192e-05, 'epoch': 0.2}
{'loss': 0.8285, 'grad_norm': 0.5383191704750061, 'learning_rate': 4.9484396200814116e-05, 'epoch': 0.21}
{'loss': 0.7959, 'grad_norm': 0.9421201348304749, 'learning_rate': 4.9481004070556313e-05, 'epoch': 0.21}

  1%|▉                                                                                        | 156/14740 [01:30<2:27:33,  1.65it/s]
{'loss': 0.7528, 'grad_norm': 0.6618213057518005, 'learning_rate': 4.947421981004071e-05, 'epoch': 0.21}
{'loss': 1.4579, 'grad_norm': 0.8201290369033813, 'learning_rate': 4.9470827679782905e-05, 'epoch': 0.21}

  1%|▉                                                                                        | 160/14740 [01:32<2:07:32,  1.91it/s]
{'loss': 1.1554, 'grad_norm': 0.6261847615242004, 'learning_rate': 4.9464043419267306e-05, 'epoch': 0.21}
{'loss': 1.3065, 'grad_norm': 0.9492092728614807, 'learning_rate': 4.94606512890095e-05, 'epoch': 0.22}
{'loss': 0.3467, 'grad_norm': 0.3373085558414459, 'learning_rate': 4.94572591587517e-05, 'epoch': 0.22}
{'loss': 0.6353, 'grad_norm': 0.4736095666885376, 'learning_rate': 4.94538670284939e-05, 'epoch': 0.22}

  1%|▉                                                                                        | 165/14740 [01:35<2:01:07,  2.01it/s]
{'loss': 1.2654, 'grad_norm': 0.6557819247245789, 'learning_rate': 4.944708276797829e-05, 'epoch': 0.22}
{'loss': 0.8694, 'grad_norm': 0.9317329525947571, 'learning_rate': 4.944369063772049e-05, 'epoch': 0.22}
{'loss': 0.9991, 'grad_norm': 0.6634288430213928, 'learning_rate': 4.944029850746269e-05, 'epoch': 0.22}

  1%|█                                                                                        | 168/14740 [01:36<2:19:50,  1.74it/s]
{'loss': 1.3195, 'grad_norm': 1.288610577583313, 'learning_rate': 4.943351424694708e-05, 'epoch': 0.23}
{'loss': 0.2623, 'grad_norm': 0.28564128279685974, 'learning_rate': 4.9430122116689285e-05, 'epoch': 0.23}

  1%|█                                                                                        | 172/14740 [01:38<2:05:06,  1.94it/s]
{'loss': 1.0062, 'grad_norm': 0.9004520177841187, 'learning_rate': 4.942333785617368e-05, 'epoch': 0.23}
{'loss': 1.5176, 'grad_norm': 0.796757698059082, 'learning_rate': 4.9419945725915876e-05, 'epoch': 0.23}
{'loss': 1.0828, 'grad_norm': 0.8577889204025269, 'learning_rate': 4.941655359565808e-05, 'epoch': 0.23}

  1%|█                                                                                        | 176/14740 [01:40<2:00:30,  2.01it/s]
{'loss': 0.866, 'grad_norm': 1.0284173488616943, 'learning_rate': 4.940976933514247e-05, 'epoch': 0.24}
{'loss': 0.1931, 'grad_norm': 0.24417810142040253, 'learning_rate': 4.940637720488467e-05, 'epoch': 0.24}
{'loss': 0.5519, 'grad_norm': 0.8679715394973755, 'learning_rate': 4.940298507462687e-05, 'epoch': 0.24}

  1%|█                                                                                        | 180/14740 [01:42<2:01:11,  2.00it/s]
{'loss': 1.1324, 'grad_norm': 0.7163426876068115, 'learning_rate': 4.939620081411126e-05, 'epoch': 0.24}
{'loss': 0.9005, 'grad_norm': 0.9028933048248291, 'learning_rate': 4.939280868385347e-05, 'epoch': 0.24}
{'loss': 0.5493, 'grad_norm': 0.5028980374336243, 'learning_rate': 4.938941655359566e-05, 'epoch': 0.24}

  1%|█                                                                                        | 184/14740 [01:45<2:10:36,  1.86it/s]
{'loss': 1.9122, 'grad_norm': 0.956437349319458, 'learning_rate': 4.938263229308006e-05, 'epoch': 0.25}
{'loss': 0.2026, 'grad_norm': 0.27465200424194336, 'learning_rate': 4.9379240162822256e-05, 'epoch': 0.25}
{'loss': 0.2838, 'grad_norm': 0.3681447505950928, 'learning_rate': 4.937584803256445e-05, 'epoch': 0.25}

  1%|█▏                                                                                       | 188/14740 [01:47<2:03:43,  1.96it/s]
{'loss': 0.2476, 'grad_norm': 0.2867520749568939, 'learning_rate': 4.9369063772048854e-05, 'epoch': 0.25}
{'loss': 1.2098, 'grad_norm': 1.4654866456985474, 'learning_rate': 4.9365671641791045e-05, 'epoch': 0.25}
{'loss': 0.4998, 'grad_norm': 0.4957769215106964, 'learning_rate': 4.936227951153324e-05, 'epoch': 0.26}

  1%|█▏                                                                                       | 192/14740 [01:49<2:01:31,  2.00it/s]
{'loss': 1.0437, 'grad_norm': 0.7666494846343994, 'learning_rate': 4.935549525101764e-05, 'epoch': 0.26}
{'loss': 1.8408, 'grad_norm': 0.8439968824386597, 'learning_rate': 4.935210312075984e-05, 'epoch': 0.26}
{'loss': 0.694, 'grad_norm': 1.2773749828338623, 'learning_rate': 4.934871099050204e-05, 'epoch': 0.26}

  1%|█▏                                                                                       | 195/14740 [01:51<2:28:06,  1.64it/s]
{'loss': 1.0954, 'grad_norm': 0.5844181180000305, 'learning_rate': 4.934192672998643e-05, 'epoch': 0.26}
{'loss': 0.6003, 'grad_norm': 0.57785964012146, 'learning_rate': 4.933853459972863e-05, 'epoch': 0.26}

  1%|█▏                                                                                       | 199/14740 [01:53<2:07:58,  1.89it/s]
{'loss': 0.2904, 'grad_norm': 0.364653617143631, 'learning_rate': 4.933175033921303e-05, 'epoch': 0.27}
{'loss': 2.2143, 'grad_norm': 1.0278581380844116, 'learning_rate': 4.932835820895523e-05, 'epoch': 0.27}
{'loss': 1.009, 'grad_norm': 0.8638227581977844, 'learning_rate': 4.9324966078697424e-05, 'epoch': 0.27}

  1%|█▏                                                                                       | 203/14740 [01:54<2:01:32,  1.99it/s]
{'loss': 1.2103, 'grad_norm': 0.7623876333236694, 'learning_rate': 4.931818181818182e-05, 'epoch': 0.27}
{'loss': 0.539, 'grad_norm': 0.8625264167785645, 'learning_rate': 4.9314789687924016e-05, 'epoch': 0.27}
{'loss': 1.2047, 'grad_norm': 0.8312586545944214, 'learning_rate': 4.931139755766622e-05, 'epoch': 0.28}

  1%|█▏                                                                                       | 207/14740 [01:56<2:00:39,  2.01it/s]
{'loss': 0.676, 'grad_norm': 0.5024435520172119, 'learning_rate': 4.9304613297150614e-05, 'epoch': 0.28}
{'loss': 0.49, 'grad_norm': 0.3599807024002075, 'learning_rate': 4.930122116689281e-05, 'epoch': 0.28}
{'loss': 0.3323, 'grad_norm': 0.4631146788597107, 'learning_rate': 4.929782903663501e-05, 'epoch': 0.28}

  1%|█▎                                                                                       | 211/14740 [01:59<2:08:21,  1.89it/s]
{'loss': 0.2405, 'grad_norm': 0.3636781871318817, 'learning_rate': 4.92910447761194e-05, 'epoch': 0.28}
{'loss': 1.2562, 'grad_norm': 1.0269309282302856, 'learning_rate': 4.928765264586161e-05, 'epoch': 0.28}
{'loss': 1.8085, 'grad_norm': 0.7985569834709167, 'learning_rate': 4.9284260515603804e-05, 'epoch': 0.29}

  1%|█▎                                                                                       | 215/14740 [02:01<2:03:58,  1.95it/s]
{'loss': 0.6232, 'grad_norm': 0.44788023829460144, 'learning_rate': 4.92774762550882e-05, 'epoch': 0.29}
{'loss': 2.3737, 'grad_norm': 1.1373692750930786, 'learning_rate': 4.9274084124830396e-05, 'epoch': 0.29}

  1%|█▎                                                                                       | 219/14740 [02:03<2:01:38,  1.99it/s]
{'loss': 0.9667, 'grad_norm': 0.6290780305862427, 'learning_rate': 4.926729986431479e-05, 'epoch': 0.29}
{'loss': 0.9233, 'grad_norm': 0.5714064836502075, 'learning_rate': 4.9263907734056994e-05, 'epoch': 0.29}
{'loss': 0.7001, 'grad_norm': 0.6680160164833069, 'learning_rate': 4.926051560379919e-05, 'epoch': 0.3}

  2%|█▎                                                                                       | 222/14740 [02:05<2:12:50,  1.82it/s]
{'loss': 1.3492, 'grad_norm': 0.9320574402809143, 'learning_rate': 4.9253731343283586e-05, 'epoch': 0.3}
{'loss': 0.9889, 'grad_norm': 0.7632608413696289, 'learning_rate': 4.925033921302578e-05, 'epoch': 0.3}
{'loss': 0.931, 'grad_norm': 0.6097072958946228, 'learning_rate': 4.924694708276798e-05, 'epoch': 0.3}

  2%|█▎                                                                                       | 226/14740 [02:07<2:03:20,  1.96it/s]
{'loss': 0.6876, 'grad_norm': 0.5565236806869507, 'learning_rate': 4.924016282225238e-05, 'epoch': 0.3}
{'loss': 0.3605, 'grad_norm': 0.8184746503829956, 'learning_rate': 4.923677069199458e-05, 'epoch': 0.31}
{'loss': 0.8429, 'grad_norm': 0.7732459902763367, 'learning_rate': 4.923337856173677e-05, 'epoch': 0.31}

  2%|█▍                                                                                       | 230/14740 [02:09<2:00:56,  2.00it/s]
{'loss': 2.2275, 'grad_norm': 1.1480209827423096, 'learning_rate': 4.922659430122117e-05, 'epoch': 0.31}
{'loss': 0.5247, 'grad_norm': 0.5723140835762024, 'learning_rate': 4.922320217096337e-05, 'epoch': 0.31}
{'loss': 1.0801, 'grad_norm': 0.4977262616157532, 'learning_rate': 4.9219810040705564e-05, 'epoch': 0.31}

  2%|█▍                                                                                       | 233/14740 [02:10<2:01:22,  1.99it/s]
{'loss': 0.1067, 'grad_norm': 0.1722046136856079, 'learning_rate': 4.9213025780189965e-05, 'epoch': 0.31}
{'loss': 0.7372, 'grad_norm': 0.5403634905815125, 'learning_rate': 4.9209633649932156e-05, 'epoch': 0.32}

  2%|█▍                                                                                       | 237/14740 [02:12<2:08:56,  1.87it/s]
{'loss': 1.2027, 'grad_norm': 0.7087690234184265, 'learning_rate': 4.920284938941656e-05, 'epoch': 0.32}
{'loss': 1.2386, 'grad_norm': 0.7604386806488037, 'learning_rate': 4.9199457259158754e-05, 'epoch': 0.32}
{'loss': 1.6271, 'grad_norm': 0.8449742197990417, 'learning_rate': 4.919606512890095e-05, 'epoch': 0.32}

  2%|█▍                                                                                       | 241/14740 [02:14<2:03:34,  1.96it/s]
{'loss': 0.5562, 'grad_norm': 0.4017159342765808, 'learning_rate': 4.9189280868385346e-05, 'epoch': 0.32}
{'loss': 0.818, 'grad_norm': 0.48174160718917847, 'learning_rate': 4.918588873812754e-05, 'epoch': 0.33}
{'loss': 0.6356, 'grad_norm': 0.4052407145500183, 'learning_rate': 4.918249660786975e-05, 'epoch': 0.33}

  2%|█▍                                                                                       | 245/14740 [02:16<2:00:12,  2.01it/s]
{'loss': 0.4606, 'grad_norm': 0.35461774468421936, 'learning_rate': 4.917571234735414e-05, 'epoch': 0.33}
{'loss': 0.2939, 'grad_norm': 0.4360622465610504, 'learning_rate': 4.917232021709634e-05, 'epoch': 0.33}
{'loss': 0.5242, 'grad_norm': 0.32807213068008423, 'learning_rate': 4.916892808683854e-05, 'epoch': 0.33}

  2%|█▌                                                                                       | 249/14740 [02:19<2:13:06,  1.81it/s]
{'loss': 0.8173, 'grad_norm': 0.5511957406997681, 'learning_rate': 4.916214382632293e-05, 'epoch': 0.34}
{'loss': 0.4581, 'grad_norm': 0.42345884442329407, 'learning_rate': 4.9158751696065134e-05, 'epoch': 0.34}
{'loss': 0.881, 'grad_norm': 0.692480742931366, 'learning_rate': 4.915535956580733e-05, 'epoch': 0.34}

  2%|█▌                                                                                       | 253/14740 [02:21<2:03:40,  1.95it/s]
{'loss': 0.7615, 'grad_norm': 0.35892271995544434, 'learning_rate': 4.9148575305291725e-05, 'epoch': 0.34}
{'loss': 1.3045, 'grad_norm': 0.7296322584152222, 'learning_rate': 4.914518317503392e-05, 'epoch': 0.34}
{'loss': 0.7187, 'grad_norm': 0.6638000011444092, 'learning_rate': 4.914179104477612e-05, 'epoch': 0.34}

  2%|█▌                                                                                       | 257/14740 [02:23<2:01:58,  1.98it/s]
{'loss': 0.5546, 'grad_norm': 0.4493407607078552, 'learning_rate': 4.913500678426052e-05, 'epoch': 0.35}
{'loss': 2.3705, 'grad_norm': 1.9641658067703247, 'learning_rate': 4.913161465400272e-05, 'epoch': 0.35}
{'loss': 1.2361, 'grad_norm': 0.8997926712036133, 'learning_rate': 4.9128222523744915e-05, 'epoch': 0.35}

  2%|█▌                                                                                       | 260/14740 [02:25<2:23:42,  1.68it/s]
{'loss': 1.2367, 'grad_norm': 0.8092165589332581, 'learning_rate': 4.912143826322931e-05, 'epoch': 0.35}
{'loss': 0.6408, 'grad_norm': 0.38111555576324463, 'learning_rate': 4.911804613297151e-05, 'epoch': 0.35}

  2%|█▌                                                                                       | 264/14740 [02:27<2:04:58,  1.93it/s]
{'loss': 0.9839, 'grad_norm': 0.5855650901794434, 'learning_rate': 4.911126187245591e-05, 'epoch': 0.36}
{'loss': 0.3206, 'grad_norm': 0.2608414888381958, 'learning_rate': 4.9107869742198105e-05, 'epoch': 0.36}
{'loss': 0.1964, 'grad_norm': 0.34686917066574097, 'learning_rate': 4.91044776119403e-05, 'epoch': 0.36}

  2%|█▌                                                                                       | 268/14740 [02:29<2:01:30,  1.98it/s]
{'loss': 0.4532, 'grad_norm': 0.3271561563014984, 'learning_rate': 4.9097693351424697e-05, 'epoch': 0.36}
{'loss': 0.7244, 'grad_norm': 0.6028221845626831, 'learning_rate': 4.9094301221166894e-05, 'epoch': 0.36}
{'loss': 1.0798, 'grad_norm': 0.7921508550643921, 'learning_rate': 4.909090909090909e-05, 'epoch': 0.36}

  2%|█▋                                                                                       | 272/14740 [02:31<2:17:37,  1.75it/s]
{'loss': 0.6152, 'grad_norm': 0.5173085331916809, 'learning_rate': 4.908412483039349e-05, 'epoch': 0.37}
{'loss': 1.3196, 'grad_norm': 0.7718061208724976, 'learning_rate': 4.908073270013569e-05, 'epoch': 0.37}

  2%|█▋                                                                                       | 276/14740 [02:33<2:04:32,  1.94it/s]
{'loss': 0.6193, 'grad_norm': 0.4637424349784851, 'learning_rate': 4.9073948439620084e-05, 'epoch': 0.37}
{'loss': 0.4621, 'grad_norm': 0.3918072581291199, 'learning_rate': 4.907055630936228e-05, 'epoch': 0.37}
{'loss': 1.023, 'grad_norm': 0.6878315806388855, 'learning_rate': 4.906716417910448e-05, 'epoch': 0.37}
{'loss': 2.0605, 'grad_norm': 2.240098714828491, 'learning_rate': 4.906377204884668e-05, 'epoch': 0.37}

  2%|█▋                                                                                       | 280/14740 [02:35<2:00:17,  2.00it/s]
{'loss': 0.1368, 'grad_norm': 0.2832837700843811, 'learning_rate': 4.9056987788331076e-05, 'epoch': 0.38}
{'loss': 1.7599, 'grad_norm': 1.1019108295440674, 'learning_rate': 4.9053595658073273e-05, 'epoch': 0.38}
{'loss': 0.1901, 'grad_norm': 0.3322219252586365, 'learning_rate': 4.905020352781547e-05, 'epoch': 0.38}

  2%|█▋                                                                                       | 284/14740 [02:37<2:00:05,  2.01it/s]
{'loss': 2.0939, 'grad_norm': 0.9285706281661987, 'learning_rate': 4.9043419267299865e-05, 'epoch': 0.38}
{'loss': 2.2691, 'grad_norm': 1.5254892110824585, 'learning_rate': 4.904002713704207e-05, 'epoch': 0.38}
{'loss': 1.103, 'grad_norm': 0.6722187399864197, 'learning_rate': 4.9036635006784266e-05, 'epoch': 0.39}

  2%|█▋                                                                                       | 287/14740 [02:39<2:15:09,  1.78it/s]
{'loss': 0.4133, 'grad_norm': 0.30995428562164307, 'learning_rate': 4.902985074626866e-05, 'epoch': 0.39}
{'loss': 0.6855, 'grad_norm': 0.5282513499259949, 'learning_rate': 4.902645861601086e-05, 'epoch': 0.39}

  2%|█▊                                                                                       | 291/14740 [02:41<2:04:16,  1.94it/s]
{'loss': 0.7818, 'grad_norm': 0.4809991717338562, 'learning_rate': 4.901967435549525e-05, 'epoch': 0.39}
{'loss': 0.585, 'grad_norm': 0.46819034218788147, 'learning_rate': 4.9016282225237456e-05, 'epoch': 0.39}
{'loss': 1.0638, 'grad_norm': 0.6152899265289307, 'learning_rate': 4.901289009497965e-05, 'epoch': 0.39}

  2%|█▊                                                                                       | 295/14740 [02:43<2:00:45,  1.99it/s]
{'loss': 0.2153, 'grad_norm': 0.5384320616722107, 'learning_rate': 4.900610583446405e-05, 'epoch': 0.4}
{'loss': 0.7696, 'grad_norm': 0.4658557176589966, 'learning_rate': 4.9002713704206245e-05, 'epoch': 0.4}
{'loss': 0.723, 'grad_norm': 0.43747076392173767, 'learning_rate': 4.899932157394844e-05, 'epoch': 0.4}

  2%|█▊                                                                                       | 299/14740 [02:45<2:19:53,  1.72it/s]
{'loss': 2.4179, 'grad_norm': 0.9333141446113586, 'learning_rate': 4.899253731343284e-05, 'epoch': 0.4}
{'loss': 1.4919, 'grad_norm': 0.8601061105728149, 'learning_rate': 4.8989145183175033e-05, 'epoch': 0.4}
{'loss': 1.0692, 'grad_norm': 0.7088128328323364, 'learning_rate': 4.898575305291723e-05, 'epoch': 0.41}

  2%|█▊                                                                                       | 303/14740 [02:47<2:06:08,  1.91it/s]
{'loss': 0.573, 'grad_norm': 0.48045167326927185, 'learning_rate': 4.897896879240163e-05, 'epoch': 0.41}
{'loss': 0.8344, 'grad_norm': 0.4629642069339752, 'learning_rate': 4.897557666214383e-05, 'epoch': 0.41}
{'loss': 0.4725, 'grad_norm': 0.39300018548965454, 'learning_rate': 4.8972184531886026e-05, 'epoch': 0.41}

  2%|█▊                                                                                       | 307/14740 [02:49<2:02:30,  1.96it/s]
{'loss': 1.7256, 'grad_norm': 1.1561973094940186, 'learning_rate': 4.896540027137042e-05, 'epoch': 0.41}
{'loss': 1.144, 'grad_norm': 0.6385267376899719, 'learning_rate': 4.896200814111262e-05, 'epoch': 0.42}
{'loss': 0.9566, 'grad_norm': 0.5258387923240662, 'learning_rate': 4.895861601085482e-05, 'epoch': 0.42}

  2%|█▉                                                                                       | 311/14740 [02:51<2:01:22,  1.98it/s]
{'loss': 1.321, 'grad_norm': 0.9259704947471619, 'learning_rate': 4.8951831750339216e-05, 'epoch': 0.42}
{'loss': 0.4066, 'grad_norm': 0.37244293093681335, 'learning_rate': 4.894843962008141e-05, 'epoch': 0.42}

  2%|█▉                                                                                       | 313/14740 [02:52<2:15:45,  1.77it/s]
{'loss': 0.6449, 'grad_norm': 0.43945470452308655, 'learning_rate': 4.894165535956581e-05, 'epoch': 0.42}
{'loss': 1.2416, 'grad_norm': 0.7940053939819336, 'learning_rate': 4.8938263229308005e-05, 'epoch': 0.42}
{'loss': 0.6324, 'grad_norm': 0.35536864399909973, 'learning_rate': 4.893487109905021e-05, 'epoch': 0.43}

  2%|█▉                                                                                       | 317/14740 [02:54<2:04:46,  1.93it/s]
{'loss': 1.642, 'grad_norm': 0.7482542991638184, 'learning_rate': 4.89280868385346e-05, 'epoch': 0.43}
{'loss': 0.9494, 'grad_norm': 0.5740201473236084, 'learning_rate': 4.89246947082768e-05, 'epoch': 0.43}
{'loss': 1.5039, 'grad_norm': 0.6792514324188232, 'learning_rate': 4.8921302578019e-05, 'epoch': 0.43}

  2%|█▉                                                                                       | 321/14740 [02:56<2:00:56,  1.99it/s]
{'loss': 0.9682, 'grad_norm': 0.5157027244567871, 'learning_rate': 4.891451831750339e-05, 'epoch': 0.43}
{'loss': 0.1345, 'grad_norm': 0.25845882296562195, 'learning_rate': 4.8911126187245596e-05, 'epoch': 0.44}
{'loss': 0.879, 'grad_norm': 0.6860952973365784, 'learning_rate': 4.890773405698779e-05, 'epoch': 0.44}

  2%|█▉                                                                                       | 325/14740 [02:58<2:15:00,  1.78it/s]
{'loss': 1.0953, 'grad_norm': 0.7803295850753784, 'learning_rate': 4.890094979647219e-05, 'epoch': 0.44}
{'loss': 0.6315, 'grad_norm': 0.465044766664505, 'learning_rate': 4.8897557666214384e-05, 'epoch': 0.44}
{'loss': 0.7574, 'grad_norm': 0.7005478143692017, 'learning_rate': 4.889416553595658e-05, 'epoch': 0.44}

  2%|█▉                                                                                       | 329/14740 [03:00<2:03:43,  1.94it/s]
{'loss': 0.4766, 'grad_norm': 0.36260583996772766, 'learning_rate': 4.888738127544098e-05, 'epoch': 0.45}
{'loss': 0.5105, 'grad_norm': 0.5178320407867432, 'learning_rate': 4.888398914518318e-05, 'epoch': 0.45}

  2%|██                                                                                       | 333/14740 [03:02<1:59:55,  2.00it/s]
{'loss': 0.5055, 'grad_norm': 0.38272780179977417, 'learning_rate': 4.8877204884667574e-05, 'epoch': 0.45}
{'loss': 0.4352, 'grad_norm': 0.3547241687774658, 'learning_rate': 4.887381275440977e-05, 'epoch': 0.45}
{'loss': 0.987, 'grad_norm': 0.6250954866409302, 'learning_rate': 4.887042062415197e-05, 'epoch': 0.45}
{'loss': 1.361, 'grad_norm': 1.0361239910125732, 'learning_rate': 4.8867028493894166e-05, 'epoch': 0.45}

  2%|██                                                                                       | 337/14740 [03:04<1:59:27,  2.01it/s]
{'loss': 0.8026, 'grad_norm': 0.528254508972168, 'learning_rate': 4.886024423337857e-05, 'epoch': 0.46}
{'loss': 1.5744, 'grad_norm': 0.7301447987556458, 'learning_rate': 4.8856852103120764e-05, 'epoch': 0.46}

  2%|██                                                                                       | 340/14740 [03:06<2:12:52,  1.81it/s]
{'loss': 0.7902, 'grad_norm': 0.41998982429504395, 'learning_rate': 4.885006784260516e-05, 'epoch': 0.46}
{'loss': 0.4588, 'grad_norm': 0.38078778982162476, 'learning_rate': 4.8846675712347356e-05, 'epoch': 0.46}
{'loss': 0.6966, 'grad_norm': 0.5347739458084106, 'learning_rate': 4.884328358208955e-05, 'epoch': 0.46}

  2%|██                                                                                       | 344/14740 [03:08<2:03:13,  1.95it/s]
{'loss': 0.4242, 'grad_norm': 0.44836732745170593, 'learning_rate': 4.8836499321573954e-05, 'epoch': 0.47}
{'loss': 0.4036, 'grad_norm': 0.48659437894821167, 'learning_rate': 4.8833107191316144e-05, 'epoch': 0.47}
{'loss': 0.7168, 'grad_norm': 0.7070636749267578, 'learning_rate': 4.882971506105835e-05, 'epoch': 0.47}

  2%|██                                                                                       | 348/14740 [03:10<2:00:26,  1.99it/s]
{'loss': 0.5719, 'grad_norm': 0.39202702045440674, 'learning_rate': 4.882293080054274e-05, 'epoch': 0.47}
{'loss': 1.191, 'grad_norm': 0.9731562733650208, 'learning_rate': 4.881953867028494e-05, 'epoch': 0.47}
{'loss': 0.4218, 'grad_norm': 0.381411075592041, 'learning_rate': 4.8816146540027144e-05, 'epoch': 0.47}

  2%|██▏                                                                                      | 352/14740 [03:13<2:13:20,  1.80it/s]
{'loss': 0.4682, 'grad_norm': 0.35349828004837036, 'learning_rate': 4.880936227951153e-05, 'epoch': 0.48}
{'loss': 1.0209, 'grad_norm': 0.5969623923301697, 'learning_rate': 4.8805970149253735e-05, 'epoch': 0.48}

  2%|██▏                                                                                      | 356/14740 [03:15<2:03:33,  1.94it/s]
{'loss': 0.2604, 'grad_norm': 0.3567679822444916, 'learning_rate': 4.879918588873813e-05, 'epoch': 0.48}
{'loss': 0.1914, 'grad_norm': 0.2291441708803177, 'learning_rate': 4.879579375848033e-05, 'epoch': 0.48}
{'loss': 0.9982, 'grad_norm': 0.6461085677146912, 'learning_rate': 4.879240162822253e-05, 'epoch': 0.48}
  2%|██▏                                                                                      | 359/14740 [03:16<2:00:59,  1.98it/s]Traceback (most recent call last):
  File "/home2/adyansh/LLM4ADR/Approach/Code/training.py", line 142, in <module>
    training_data = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 184, in forward
    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 189, in replicate
    return replicate(module, device_ids, not torch.is_grad_enabled())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/parallel/replicate.py", line 134, in replicate
    replica = module._replicate_for_data_parallel()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2527, in _replicate_for_data_parallel
    replica._modules = replica._modules.copy()
                       ^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
{'loss': 1.1463, 'grad_norm': 0.8094252347946167, 'learning_rate': 4.878561736770692e-05, 'epoch': 0.49}
{'loss': 1.0986, 'grad_norm': 0.5581265091896057, 'learning_rate': 4.878222523744912e-05, 'epoch': 0.49}