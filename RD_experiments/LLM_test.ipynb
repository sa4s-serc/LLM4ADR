{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Context We need to decide on which database management system (DBMS) to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\n",
      "### Decision Considerations\n",
      "- Ease of use and maintenance\n",
      "- Community support and resources\n",
      "- Performance and scalability\n",
      "- Security and reliability\n",
      "- Cost and licensing\n",
      "- Compatibility with our technology stack\n",
      "### Considered Options\n",
      "- MySQL\n",
      "- PostgreSQL\n",
      "- Oracle\n",
      "- Microsoft SQL Server\n",
      "- MongoDB\n",
      "\n",
      "## Decision\n",
      "\n",
      "After evaluating the above options based on our decision considerations, we have decided to choose MySQL as our DBMS for Project X.\n",
      "\n",
      "MySQL is a popular open-source system with a strong development community and a large pool of resources for problem-solving and knowledge sharing. It is well-known for its excellent performance and scalability capabilities, making it ideal for handling vast amounts of data with high levels of efficiency. The platform is secure, reliable, and has a wide range of features that are essential for our project, including ACID compliance for transactions, flexible data model, and support for various programming languages and frameworks.\n",
      "\n",
      "MySQL is also compatible with the majority of our technology stack, including our web development framework, hosting solutions, and other essential tools. Plus, its cost and licensing terms are competitive compared to other proprietary systems like Oracle and Microsoft SQL Server.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"This is an Architectural Decision Record for a software. Give a ## Decision corresponding to the ## Context provided by the User.\"\n",
    "Context = \"## Context We need to decide on which database management system (DBMS) to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\\n### Decision Considerations\\n- Ease of use and maintenance\\n- Community support and resources\\n- Performance and scalability\\n- Security and reliability\\n- Cost and licensing\\n- Compatibility with our technology stack\\n### Considered Options\\n- MySQL\\n- PostgreSQL\\n- Oracle\\n- Microsoft SQL Server\\n- MongoDB\\n\"\n",
    "print(Context)\n",
    "Decision = \"## Decision\\n\\nAfter evaluating the above options based on our decision considerations, we have decided to choose MySQL as our DBMS for Project X.\\n\\nMySQL is a popular open-source system with a strong development community and a large pool of resources for problem-solving and knowledge sharing. It is well-known for its excellent performance and scalability capabilities, making it ideal for handling vast amounts of data with high levels of efficiency. The platform is secure, reliable, and has a wide range of features that are essential for our project, including ACID compliance for transactions, flexible data model, and support for various programming languages and frameworks.\\n\\nMySQL is also compatible with the majority of our technology stack, including our web development framework, hosting solutions, and other essential tools. Plus, its cost and licensing terms are competitive compared to other proprietary systems like Oracle and Microsoft SQL Server.\"\n",
    "print(Decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "path = '/home2/rudra.dhar/codes/SE/ADR/experiments/'\n",
    "load_dotenv(path + '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "We have decided to use MySQL as the DBMS for Project X.\n",
      "\n",
      "### Rationale\n",
      "After careful evaluation of the considered options, we believe that MySQL is the best fit for our needs. Here are the reasons for our decision:\n",
      "\n",
      "- **Ease of use and maintenance:** MySQL is known for its user-friendly interface and ease of use. It also has a large community of users and developers, which provides ample support and resources.\n",
      "- **Performance and scalability:** MySQL is a high-performance DBMS that can handle large amounts of data and concurrent transactions. It also offers scalability options to meet the growing needs of our application.\n",
      "- **Security and reliability:** MySQL provides robust security features to protect data from unauthorized access and breaches. It also offers high reliability with features such as replication and failover.\n",
      "- **Cost and licensing:** MySQL is a cost-effective option compared to other commercial DBMSs. It is open source and has a flexible licensing model that suits our budget and usage requirements.\n",
      "- **Compatibility with our technology stack:** MySQL is compatible with our existing technology stack, which includes PHP, Python, and Node.js. This ensures seamless integration and reduces development efforts.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the command line, only need to run once to install the package via pip:\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "google_key = os.getenv('google_key')\n",
    "\n",
    "genai.configure(api_key=google_key)\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.5,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2048,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
    "                              generation_config=generation_config)\n",
    "\n",
    "convo = model.start_chat(history=[])\n",
    "\n",
    "convo.send_message(system_message+ \"\\n\\n\" +Context)\n",
    "print(convo.last.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "\n",
      "After evaluating the options against our decision considerations, we have decided to use MySQL as the database management system for Project X. The rationale for this decision is as follows:\n",
      "\n",
      "1. Ease of use and maintenance:\n",
      "   - MySQL offers a user-friendly interface and comprehensive documentation, making it easier for developers to work with and maintain the database.\n",
      "   - It has a large and active community, providing extensive resources, tutorials, and forums for support.\n",
      "\n",
      "2. Community support and resources:\n",
      "   - MySQL has a vast and vibrant community, ensuring access to a wide range of resources, including documentation, tutorials, and forums.\n",
      "   - The community actively contributes to the development and improvement of MySQL, providing regular updates and bug fixes.\n",
      "\n",
      "3. Performance and scalability:\n",
      "   - MySQL delivers high performance for read-heavy workloads, which aligns well with our project requirements.\n",
      "   - It offers various scalability options, such as replication and partitioning, allowing us to handle increasing data volumes and user loads.\n",
      "\n",
      "4. Security and reliability:\n",
      "   - MySQL provides robust security features, including user authentication, access control, and data encryption.\n",
      "   - It has a proven track record of reliability and is widely used in enterprise-level applications.\n",
      "\n",
      "5. Cost and licensing:\n",
      "   - MySQL is available under an open-source license, which means no upfront costs for licensing.\n",
      "   - It offers a cost-effective solution compared to proprietary alternatives like Oracle or Microsoft SQL Server.\n",
      "\n",
      "6. Compatibility with our technology stack:\n",
      "   - MySQL integrates well with our existing technology stack, which includes programming languages like PHP, Python, and Java.\n",
      "   - It has extensive driver support and ORM (Object-Relational Mapping) libraries available for seamless integration.\n",
      "\n",
      "While other options like PostgreSQL and MongoDB were considered, MySQL emerged as the most suitable choice based on our specific requirements and considerations. Its combination of ease of use, community support, performance, security, cost-effectiveness, and compatibility makes it the ideal DBMS for Project X.\n",
      "\n",
      "We acknowledge that there may be trade-offs, such as limited support for complex data types compared to PostgreSQL or the lack of native document storage capabilities offered by MongoDB. However, given our primary focus on handling large amounts of structured data and the need for strong transaction support, MySQL aligns best with our current needs.\n",
      "\n",
      "Moving forward, we will proceed with the implementation of MySQL as the DBMS for Project X. We will ensure proper configuration, optimization, and security measures are in place to maximize its potential and meet our project requirements effectively.\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic_key = os.getenv('anthropic_key')\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": Context\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIIIT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLAB_SE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mADR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLM4ADR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRD_experiments\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m load_dotenv(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m openai_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai_key_karthik\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key \u001b[38;5;241m=\u001b[39m openai_key)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "\n",
    "openai_key = os.getenv('openai_key_karthik')\n",
    "\n",
    "client = OpenAI(api_key = openai_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": Context\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "After evaluating the options based on the decision considerations, we have decided to go with PostgreSQL as our DBMS for Project X. PostgreSQL is a widely used, open-source relational DBMS with robust community support and resources. It offers high performance, scalability, security, and ease of use, making it suitable for handling large amounts of data from multiple sources. While it may not be as fast as some other options, it excels in ACID compliance and provides strong data security, which are crucial for our project requirements.\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "cohere_key = os.getenv('cohere_key')\n",
    "\n",
    "co = cohere.Client(\n",
    "    api_key=cohere_key, # This is your trial API key\n",
    ") \n",
    "\n",
    "stream = co.chat_stream( \n",
    "    model='command-r-plus',\n",
    "    message=system_message+Context,\n",
    "    temperature=0.3,\n",
    "    chat_history=[],\n",
    "    prompt_truncation='AUTO',\n",
    "    connectors=[{\"id\":\"web-search\"}]\n",
    ") \n",
    "\n",
    "response_text = ''\n",
    "for event in stream:\n",
    "    if event.event_type == \"text-generation\":\n",
    "        response_text += event.text\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client(cohere_key) # This is your trial API key\n",
    "\n",
    "response = co.embed(\n",
    "  model='embed-english-v3.0',\n",
    "  texts=[Context],\n",
    "  input_type='classification',\n",
    "  truncate='NONE'\n",
    ")\n",
    "embeddings = response.embeddings\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'The model meta-llama/Meta-Llama-3-8B is too large to be loaded automatically (16GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-core in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (2.19.1)\n",
      "Requirement already satisfied: google-cloud-core in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (2.4.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (1.59.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl (5.1 MB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (2.31.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (2.32.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.63.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.24.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.17.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.0.5)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.10.12)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.12.4)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.62.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.65.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (4.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy<3,>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.21.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  WARNING: The script tb-gcp-uploader.exe is installed in 'C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.59.0\n",
      "    Uninstalling google-cloud-aiplatform-1.59.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.59.0\n",
      "Successfully installed google-cloud-aiplatform-1.60.0\n"
     ]
    }
   ],
   "source": [
    "# %pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to authenticate by gcloud CLI. Install:\n",
    "https://cloud.google.com/sdk/docs/install#windows\n",
    "\n",
    "VertexAi configuration: Endpoint, Models:\n",
    "https://console.cloud.google.com/vertex-ai\n",
    "\n",
    "Go to vertexAI -> Model Garden -> Llama3 -> Deploy \\\n",
    "It will take about half an hour to deploy\n",
    "\n",
    "set env variable gcp_endpoint to endpoint id \\\n",
    "Get Project number from project page and set project=\"project_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DatasetServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.dataset_service' (most likely due to a circular import) (C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import google.protobuf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvertexai\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m aiplatform_version\n\u001b[0;32m     21\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m aiplatform_version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     ImageDataset,\n\u001b[0;32m     28\u001b[0m     TabularDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     VideoDataset,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleAuthError\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m constants\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\compat\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m services\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[0;32m     21\u001b[0m V1BETA1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1beta1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\compat\\services\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m dataset_service_client_v1beta1,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeployment_resource_pool_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m deployment_resource_pool_service_client_v1beta1,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoint_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m endpoint_service_client_v1beta1,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2024 Google LLC\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceClient\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceAsyncClient\n\u001b[0;32m     19\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetServiceClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetServiceAsyncClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\client.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Dict,\n\u001b[0;32m     21\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     cast,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapic_version \u001b[38;5;28;01mas\u001b[39;00m package_version\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m client_options \u001b[38;5;28;01mas\u001b[39;00m client_options_lib\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m core_exceptions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapic_version \u001b[38;5;28;01mas\u001b[39;00m package_version\n\u001b[0;32m     18\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m package_version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceClient\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceAsyncClient\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeployment_resource_pool_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     DeploymentResourcePoolServiceClient,\n\u001b[0;32m     25\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DatasetServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.dataset_service' (most likely due to a circular import) (C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "# import google.protobuf\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "gcp_endpoint = os.getenv('gcp_endpoint')\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "project_number = \"803768827144\"\n",
    "vertexai.init(project=project_number, location=\"us-east4\")\n",
    "\n",
    "# Get the endpoint\n",
    "endpoint = aiplatform.Endpoint(gcp_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "messages = [{\"prompt\": \"What is the capital of France?\"},\n",
    "            {\"prompt\": \"tell me a story?\"}]\n",
    "        \n",
    "# messages = [{\"prompt\": Context}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'predictions': ['Prompt:\\n'\n",
      "                  'What is the capital of France?\\n'\n",
      "                  'Output:\\n'\n",
      "                  ' Paris.\\n'\n",
      "                  'Which sport is played on a frozen pond in Canada? Hockey.\\n'\n",
      "                  'What']},\n",
      " {'predictions': ['Prompt:\\n'\n",
      "                  'tell me a story?\\n'\n",
      "                  'Output:\\n'\n",
      "                  ' :D!\\n'\n",
      "                  '\\n'\n",
      "                  'Once upon a time, in a small village nestled in the '\n",
      "                  'rolling']}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"maxOutputTokens\": 1,\n",
    "    # \"topK\": 40,\n",
    "    # \"topP\": 0.95\n",
    "  }\n",
    "\n",
    "response = endpoint.predict(instances=messages, parameters=parameters)\n",
    "pprint(response.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2022.9.14)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Architectural Decision Record:\n",
      "\n",
      "**## Decision**\n",
      "\n",
      "We will use **PostgreSQL** as the database management system (DBMS) for Project X.\n",
      "\n",
      "**## Context**\n",
      "We need to decide on which DBMS to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\n",
      "\n",
      "**## Decision Rationale**\n",
      "\n",
      "After weighing the considerations and evaluating the options, we have decided on PostgreSQL for several reasons:\n",
      "\n",
      "* **Ease of use and maintenance**: PostgreSQL has a reputation for being easy to learn and maintain, with a large community of developers who contribute to its documentation and provide support.\n",
      "* **Community support and resources**: As an open-source database, PostgreSQL has a vast community of users and contributors, ensuring that there will always be someone available to help with any issues or questions we may have.\n",
      "* **Performance and scalability**: PostgreSQL is designed to handle large amounts of data and offers excellent performance and scalability features, making it well-suited for Project X's needs.\n",
      "* **Security and reliability**: PostgreSQL has a strong focus on security and reliability, with features like encryption, backups, and replication ensuring that our data is safe and available even in the event of an outage.\n",
      "* **Cost and licensing**: As an open-source database, PostgreSQL eliminates the need for costly licenses or subscription fees.\n",
      "* **Compatibility with our technology stack**: PostgreSQL has excellent support for various programming languages and frameworks, ensuring seamless integration with our chosen technologies.\n",
      "\n",
      "**## Conclusion**\n",
      "\n",
      "After careful consideration of all options, we have decided to use PostgreSQL as the DBMS for Project X. This decision was based on a thorough evaluation of the considerations and options, and we believe that PostgreSQL will provide us with a reliable, scalable, and secure database solution that meets our needs.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='llama3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': system_message+Context,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "# load_dotenv(os.path.join(path, '.env'))\n",
    "# huggingface_token = os.getenv('Huggingface_Rudra')\n",
    "\n",
    "huggingface_token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf23431327246ca98cf777494046ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\", token=huggingface_token, cache_dir='/scratch/rudra.dhar/cache')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-9b-it\", device_map=\"auto\", torch_dtype=torch.bfloat16, token=huggingface_token, cache_dir='/scratch/rudra.dhar/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>This is an Architectural Decision Record for a software. Give a ## Decision corresponding to the ## Context provided by the User.## Context We need to decide on which database management system (DBMS) to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\n",
      "### Decision Considerations\n",
      "- Ease of use and maintenance\n",
      "- Community support and resources\n",
      "- Performance and scalability\n",
      "- Security and reliability\n",
      "- Cost and licensing\n",
      "- Compatibility with our technology stack\n",
      "### Considered Options\n",
      "- MySQL\n",
      "- PostgreSQL\n",
      "- Oracle\n",
      "- Microsoft SQL Server\n",
      "- MongoDB\n",
      "### Decision\n",
      "We will use **MySQL** as the DBMS for Project X.\n",
      "\n",
      "### Rationale\n",
      "MySQL was chosen based on the following factors:\n",
      "\n",
      "- **Ease of use and maintenance:** MySQL is known for its user-friendly interface and relatively straightforward administration.\n",
      "- **Community support and resources:** MySQL has a large and active community, providing ample support, documentation, and third-party tools.\n",
      "- **Performance and scalability:** MySQL offers good performance for read and write operations and can be scaled horizontally to handle increasing data volumes.\n",
      "- **Security and reliability:** MySQL provides robust security features and mechanisms for ensuring data integrity and availability.\n",
      "- **Cost and licensing:** MySQL offers both open-source and commercial licensing options, making it cost-effective for our project.\n",
      "- **Compatibility with our technology stack:** MySQL is compatible with the programming languages and frameworks we are using for Project X.\n",
      "\n",
      "### Risks and Mitigations\n",
      "- **Limited advanced features:** Compared to some other DBMS options, MySQL may have fewer advanced features for complex data models or analytical workloads.\n",
      "    - **Mitigation:** We will carefully evaluate our data modeling requirements and explore potential workarounds or extensions if necessary.\n",
      "- **Scalability limitations:** While MySQL can be scaled horizontally, there may be limitations in handling extremely large datasets or high transaction volumes.\n",
      "    - **Mitigation:** We will monitor performance closely and consider sharding or other scaling techniques if required.\n",
      "\n",
      "### Decision Owner\n",
      "[Name of Decision Owner]\n",
      "\n",
      "### Date\n",
      "[Date of Decision]<end_of_turn>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "input_text = system_message + Context\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=1000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home2/rudra.dhar/miniconda3/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in ./miniconda3/lib/python3.10/site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./miniconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch) (1.2.1)\n",
      "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m664.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0mm00:22\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m751.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:14\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0mm\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home2/rudra.dhar/miniconda3/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: typing-extensions, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home2/rudra.dhar/miniconda3/lib/python3.10/site-packages/~vfuser'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home2/rudra.dhar/miniconda3/lib/python3.10/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.0.2 requires torch==2.0.1, but you have torch 2.4.0 which is incompatible.\n",
      "torchvision 0.15.2 requires torch==2.0.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0 typing-extensions-4.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
