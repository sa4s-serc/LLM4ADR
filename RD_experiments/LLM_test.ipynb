{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Context We need to decide on which database management system (DBMS) to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\n",
      "### Decision Considerations\n",
      "- Ease of use and maintenance\n",
      "- Community support and resources\n",
      "- Performance and scalability\n",
      "- Security and reliability\n",
      "- Cost and licensing\n",
      "- Compatibility with our technology stack\n",
      "### Considered Options\n",
      "- MySQL\n",
      "- PostgreSQL\n",
      "- Oracle\n",
      "- Microsoft SQL Server\n",
      "- MongoDB\n",
      "\n",
      "## Decision\n",
      "\n",
      "After evaluating the above options based on our decision considerations, we have decided to choose MySQL as our DBMS for Project X.\n",
      "\n",
      "MySQL is a popular open-source system with a strong development community and a large pool of resources for problem-solving and knowledge sharing. It is well-known for its excellent performance and scalability capabilities, making it ideal for handling vast amounts of data with high levels of efficiency. The platform is secure, reliable, and has a wide range of features that are essential for our project, including ACID compliance for transactions, flexible data model, and support for various programming languages and frameworks.\n",
      "\n",
      "MySQL is also compatible with the majority of our technology stack, including our web development framework, hosting solutions, and other essential tools. Plus, its cost and licensing terms are competitive compared to other proprietary systems like Oracle and Microsoft SQL Server.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"This is an Architectural Decision Record for a software. Give a ## Decision corresponding to the ## Context provided by the User.\"\n",
    "Context = \"## Context We need to decide on which database management system (DBMS) to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\\n### Decision Considerations\\n- Ease of use and maintenance\\n- Community support and resources\\n- Performance and scalability\\n- Security and reliability\\n- Cost and licensing\\n- Compatibility with our technology stack\\n### Considered Options\\n- MySQL\\n- PostgreSQL\\n- Oracle\\n- Microsoft SQL Server\\n- MongoDB\\n\"\n",
    "print(Context)\n",
    "Decision = \"## Decision\\n\\nAfter evaluating the above options based on our decision considerations, we have decided to choose MySQL as our DBMS for Project X.\\n\\nMySQL is a popular open-source system with a strong development community and a large pool of resources for problem-solving and knowledge sharing. It is well-known for its excellent performance and scalability capabilities, making it ideal for handling vast amounts of data with high levels of efficiency. The platform is secure, reliable, and has a wide range of features that are essential for our project, including ACID compliance for transactions, flexible data model, and support for various programming languages and frameworks.\\n\\nMySQL is also compatible with the majority of our technology stack, including our web development framework, hosting solutions, and other essential tools. Plus, its cost and licensing terms are competitive compared to other proprietary systems like Oracle and Microsoft SQL Server.\"\n",
    "print(Decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "path = '/home2/rudra.dhar/codes/SE/ADR/experiments/'\n",
    "load_dotenv(path + '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "We have decided to use MySQL as the DBMS for Project X.\n",
      "\n",
      "### Rationale\n",
      "After careful evaluation of the considered options, we believe that MySQL is the best fit for our needs. Here are the reasons for our decision:\n",
      "\n",
      "- **Ease of use and maintenance:** MySQL is known for its user-friendly interface and ease of use. It also has a large community of users and developers, which provides ample support and resources.\n",
      "- **Performance and scalability:** MySQL is a high-performance DBMS that can handle large amounts of data and concurrent transactions. It also offers scalability options to meet the growing needs of our application.\n",
      "- **Security and reliability:** MySQL provides robust security features to protect data from unauthorized access and breaches. It also offers high reliability with features such as replication and failover.\n",
      "- **Cost and licensing:** MySQL is a cost-effective option compared to other commercial DBMSs. It is open source and has a flexible licensing model that suits our budget and usage requirements.\n",
      "- **Compatibility with our technology stack:** MySQL is compatible with our existing technology stack, which includes PHP, Python, and Node.js. This ensures seamless integration and reduces development efforts.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the command line, only need to run once to install the package via pip:\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "google_key = os.getenv('google_key')\n",
    "\n",
    "genai.configure(api_key=google_key)\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.5,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2048,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
    "                              generation_config=generation_config)\n",
    "\n",
    "convo = model.start_chat(history=[])\n",
    "\n",
    "convo.send_message(system_message+ \"\\n\\n\" +Context)\n",
    "print(convo.last.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "\n",
      "After evaluating the options against our decision considerations, we have decided to use MySQL as the database management system for Project X. The rationale for this decision is as follows:\n",
      "\n",
      "1. Ease of use and maintenance:\n",
      "   - MySQL offers a user-friendly interface and comprehensive documentation, making it easier for developers to work with and maintain the database.\n",
      "   - It has a large and active community, providing extensive resources, tutorials, and forums for support.\n",
      "\n",
      "2. Community support and resources:\n",
      "   - MySQL has a vast and vibrant community, ensuring access to a wide range of resources, including documentation, tutorials, and forums.\n",
      "   - The community actively contributes to the development and improvement of MySQL, providing regular updates and bug fixes.\n",
      "\n",
      "3. Performance and scalability:\n",
      "   - MySQL delivers high performance for read-heavy workloads, which aligns well with our project requirements.\n",
      "   - It offers various scalability options, such as replication and partitioning, allowing us to handle increasing data volumes and user loads.\n",
      "\n",
      "4. Security and reliability:\n",
      "   - MySQL provides robust security features, including user authentication, access control, and data encryption.\n",
      "   - It has a proven track record of reliability and is widely used in enterprise-level applications.\n",
      "\n",
      "5. Cost and licensing:\n",
      "   - MySQL is available under an open-source license, which means no upfront costs for licensing.\n",
      "   - It offers a cost-effective solution compared to proprietary alternatives like Oracle or Microsoft SQL Server.\n",
      "\n",
      "6. Compatibility with our technology stack:\n",
      "   - MySQL integrates well with our existing technology stack, which includes programming languages like PHP, Python, and Java.\n",
      "   - It has extensive driver support and ORM (Object-Relational Mapping) libraries available for seamless integration.\n",
      "\n",
      "While other options like PostgreSQL and MongoDB were considered, MySQL emerged as the most suitable choice based on our specific requirements and considerations. Its combination of ease of use, community support, performance, security, cost-effectiveness, and compatibility makes it the ideal DBMS for Project X.\n",
      "\n",
      "We acknowledge that there may be trade-offs, such as limited support for complex data types compared to PostgreSQL or the lack of native document storage capabilities offered by MongoDB. However, given our primary focus on handling large amounts of structured data and the need for strong transaction support, MySQL aligns best with our current needs.\n",
      "\n",
      "Moving forward, we will proceed with the implementation of MySQL as the DBMS for Project X. We will ensure proper configuration, optimization, and security measures are in place to maximize its potential and meet our project requirements effectively.\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic_key = os.getenv('anthropic_key')\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": Context\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIIIT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLAB_SE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mADR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLM4ADR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRD_experiments\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m load_dotenv(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m openai_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai_key_karthik\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key \u001b[38;5;241m=\u001b[39m openai_key)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "\n",
    "openai_key = os.getenv('openai_key_karthik')\n",
    "\n",
    "client = OpenAI(api_key = openai_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": Context\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decision\n",
      "After evaluating the options based on the decision considerations, we have decided to go with PostgreSQL as our DBMS for Project X. PostgreSQL is a widely used, open-source relational DBMS with robust community support and resources. It offers high performance, scalability, security, and ease of use, making it suitable for handling large amounts of data from multiple sources. While it may not be as fast as some other options, it excels in ACID compliance and provides strong data security, which are crucial for our project requirements.\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "cohere_key = os.getenv('cohere_key')\n",
    "\n",
    "co = cohere.Client(\n",
    "    api_key=cohere_key, # This is your trial API key\n",
    ") \n",
    "\n",
    "stream = co.chat_stream( \n",
    "    model='command-r-plus',\n",
    "    message=system_message+Context,\n",
    "    temperature=0.3,\n",
    "    chat_history=[],\n",
    "    prompt_truncation='AUTO',\n",
    "    connectors=[{\"id\":\"web-search\"}]\n",
    ") \n",
    "\n",
    "response_text = ''\n",
    "for event in stream:\n",
    "    if event.event_type == \"text-generation\":\n",
    "        response_text += event.text\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client(cohere_key) # This is your trial API key\n",
    "\n",
    "response = co.embed(\n",
    "  model='embed-english-v3.0',\n",
    "  texts=[Context],\n",
    "  input_type='classification',\n",
    "  truncate='NONE'\n",
    ")\n",
    "embeddings = response.embeddings\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'The model meta-llama/Meta-Llama-3-8B is too large to be loaded automatically (16GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-core in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (2.19.1)\n",
      "Requirement already satisfied: google-cloud-core in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (2.4.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (1.59.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl (5.1 MB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (2.31.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (2.32.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.63.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.24.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.17.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.0.5)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.10.12)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.12.4)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.62.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core) (1.65.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core) (4.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy<3,>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.21.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  WARNING: The script tb-gcp-uploader.exe is installed in 'C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\rudra\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.59.0\n",
      "    Uninstalling google-cloud-aiplatform-1.59.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.59.0\n",
      "Successfully installed google-cloud-aiplatform-1.60.0\n"
     ]
    }
   ],
   "source": [
    "# %pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to authenticate by gcloud CLI. Install:\n",
    "https://cloud.google.com/sdk/docs/install#windows\n",
    "\n",
    "VertexAi configuration: Endpoint, Models:\n",
    "https://console.cloud.google.com/vertex-ai\n",
    "\n",
    "Go to vertexAI -> Model Garden -> Llama3 -> Deploy \\\n",
    "It will take about half an hour to deploy\n",
    "\n",
    "set env variable gcp_endpoint to endpoint id \\\n",
    "Get Project number from project page and set project=\"project_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DatasetServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.dataset_service' (most likely due to a circular import) (C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import google.protobuf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvertexai\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m aiplatform_version\n\u001b[0;32m     21\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m aiplatform_version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     ImageDataset,\n\u001b[0;32m     28\u001b[0m     TabularDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     VideoDataset,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleAuthError\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m constants\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\compat\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m services\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[0;32m     21\u001b[0m V1BETA1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1beta1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\compat\\services\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m dataset_service_client_v1beta1,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeployment_resource_pool_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m deployment_resource_pool_service_client_v1beta1,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoint_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     client \u001b[38;5;28;01mas\u001b[39;00m endpoint_service_client_v1beta1,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2024 Google LLC\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceClient\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceAsyncClient\n\u001b[0;32m     19\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetServiceClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetServiceAsyncClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\client.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Dict,\n\u001b[0;32m     21\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     cast,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapic_version \u001b[38;5;28;01mas\u001b[39;00m package_version\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m client_options \u001b[38;5;28;01mas\u001b[39;00m client_options_lib\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m core_exceptions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1beta1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapic_version \u001b[38;5;28;01mas\u001b[39;00m package_version\n\u001b[0;32m     18\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m package_version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceClient\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetServiceAsyncClient\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeployment_resource_pool_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     DeploymentResourcePoolServiceClient,\n\u001b[0;32m     25\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DatasetServiceClient' from partially initialized module 'google.cloud.aiplatform_v1beta1.services.dataset_service' (most likely due to a circular import) (C:\\Users\\Rudra\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1beta1\\services\\dataset_service\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "# import google.protobuf\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "path = 'D:\\IIIT\\LAB_SE\\ADR\\LLM4ADR\\RD_experiments'\n",
    "load_dotenv(os.path.join(path, '.env'))\n",
    "gcp_endpoint = os.getenv('gcp_endpoint')\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "project_number = \"803768827144\"\n",
    "vertexai.init(project=project_number, location=\"us-east4\")\n",
    "\n",
    "# Get the endpoint\n",
    "endpoint = aiplatform.Endpoint(gcp_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "messages = [{\"prompt\": \"What is the capital of France?\"},\n",
    "            {\"prompt\": \"tell me a story?\"}]\n",
    "        \n",
    "# messages = [{\"prompt\": Context}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'predictions': ['Prompt:\\n'\n",
      "                  'What is the capital of France?\\n'\n",
      "                  'Output:\\n'\n",
      "                  ' Paris.\\n'\n",
      "                  'Which sport is played on a frozen pond in Canada? Hockey.\\n'\n",
      "                  'What']},\n",
      " {'predictions': ['Prompt:\\n'\n",
      "                  'tell me a story?\\n'\n",
      "                  'Output:\\n'\n",
      "                  ' :D!\\n'\n",
      "                  '\\n'\n",
      "                  'Once upon a time, in a small village nestled in the '\n",
      "                  'rolling']}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"maxOutputTokens\": 1,\n",
    "    # \"topK\": 40,\n",
    "    # \"topP\": 0.95\n",
    "  }\n",
    "\n",
    "response = endpoint.predict(instances=messages, parameters=parameters)\n",
    "pprint(response.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2022.9.14)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Architectural Decision Record:\n",
      "\n",
      "**## Decision**\n",
      "\n",
      "We will use **PostgreSQL** as the database management system (DBMS) for Project X.\n",
      "\n",
      "**## Context**\n",
      "We need to decide on which DBMS to use for Project X. The database will be used to store and manage large amounts of data from multiple sources. We need a DBMS that can handle transactions, offer scalability, and provide high reliability and security. Among various options available, we are considering MySQL as a possible choice.\n",
      "\n",
      "**## Decision Rationale**\n",
      "\n",
      "After weighing the considerations and evaluating the options, we have decided on PostgreSQL for several reasons:\n",
      "\n",
      "* **Ease of use and maintenance**: PostgreSQL has a reputation for being easy to learn and maintain, with a large community of developers who contribute to its documentation and provide support.\n",
      "* **Community support and resources**: As an open-source database, PostgreSQL has a vast community of users and contributors, ensuring that there will always be someone available to help with any issues or questions we may have.\n",
      "* **Performance and scalability**: PostgreSQL is designed to handle large amounts of data and offers excellent performance and scalability features, making it well-suited for Project X's needs.\n",
      "* **Security and reliability**: PostgreSQL has a strong focus on security and reliability, with features like encryption, backups, and replication ensuring that our data is safe and available even in the event of an outage.\n",
      "* **Cost and licensing**: As an open-source database, PostgreSQL eliminates the need for costly licenses or subscription fees.\n",
      "* **Compatibility with our technology stack**: PostgreSQL has excellent support for various programming languages and frameworks, ensuring seamless integration with our chosen technologies.\n",
      "\n",
      "**## Conclusion**\n",
      "\n",
      "After careful consideration of all options, we have decided to use PostgreSQL as the DBMS for Project X. This decision was based on a thorough evaluation of the considerations and options, and we believe that PostgreSQL will provide us with a reliable, scalable, and secure database solution that meets our needs.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='llama3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': system_message+Context,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
