{"id": 2526, "context": "## Context and Problem Statement\nAs any modern system, Volley Management faces a problem of concurrent changes to data and we need to support such scenario.\nWe explicitly do not consider an option to go without concurrency checks - time will tell if it is a good decision).\n## Decision Drivers <!-- optional -->\n* Performance - decision should support high throughput scenarios\n* Maintainability - amount of code needed to write should be minimized\n"}
{"id": 873, "context": "## Context\n- Originally we wanted to use just PointerEvents API for capturing events because the API covers mouse and pointer inputs.\n- Unfortunately Safari and iOS have very limited support. Safari does currently have an experimental API for it but the movementX and movementY properties are always 0.\n- MovementX/Y is a clean browser only method for determining distance without having to track previous coordinates.\n- Mobile is a secondary concern for this app, but pointer events on desktop Safari is also unsupported :(\n"}
{"id": 1740, "context": "## Context\nBookit needs a persistence mechanism.  There are many to choose from that fit an application's needs.  Currently, we believe a SQL/RDBMS approach fits better than NoSQL.  There's not a lot of context to add to that, just a quick poll of the engineers when we kicked off the project.  With that in mind, we wanted something hosted/PaaS.\nGiven we're in AWS, RDS is an obvious choice.  We don't currently have a preference for DB vendor/implementation, but are drawn to open source and free.  MySql and PostgreSql fit that criteria.\nFurther, AWS RDS has their own MySql implementation which provides much better performance and up to the minute backups with no degredation for fractions of a penny/hr more than the standard MySql over RDS.  And while Bookit's usage might not warrant the need for higher performance, there is always a need for high availability and Aurora provides that in a very hands off way.  There is also an Aurora implentation for PostgreSql but at the time of this decision, that is in Preview so we decided to skip it.\n"}
{"id": 2626, "context": "## Context\nThe software could be developed in one big (Gradle) project.\nThis would make integration easier.\nAt the same time this would make re-use of the code outside of this project harder.\nOne big project would probably lead to worse code since there would not be the need to have defined API boundaries.\n"}
{"id": 3966, "context": "## Context\nPIMS requires a database to store all property information.\nThe data is relational, requiring constraints and must run within a Linux docker container on OpenShift.\nAdditionally it must be supported by Entity Framework Core 3.1.\n"}
{"id": 3521, "context": "## Context and Problem Statement\nWe found that without a standardised format our javascript files ended up with different\nformats in different files or even multiple formats in the same file.  We also found that\nour IDEs had different configurations which meant that using an autoformat tool would give\ndifferent results when each of us do it.\n## Decision Drivers\n* We wanted to spend less time doing manual formatting\n* We wanted to spend less time undoing autoformatting which had been applied to unchanged lines\n* We wanted to see easily which lines had actually changed when reviewing PRs\n* We wanted to avoid discussions about individual's preferences for particular\n"}
{"id": 1228, "context": "## Context and Problem Statement\nHow to guarantee reproducibility of Jupyter Notebooks?\nIn order to allow any user to re run the notebook with similar behaviour, it's important that each notebook is shipped with dependencies requirements\nthat include direct and transitive dependencies. This would also enforce and support security, reproducibility, traecability.\nNotebooks should be treated as component/service that use their own dependencies, therefore when storing notebooks,\nthey should be stored with dependencies so that an image can be built to run them or they can be shared and reused by others.\n## Decision Drivers <!-- optional -->\n* user prospective\n* reproducibility\n* traecability\n"}
{"id": 2127, "context": "## Context\nIn order to have a distributed version of James we need to have an homogeneous way to deal with `Task`.\nCurrently, every James nodes of a cluster have their own instance of `TaskManager` and they have no knowledge of others, making it impossible to orchestrate task execution at the cluster level.\nTasks are scheduled and ran on the same node they are scheduled.\nWe are also unable to list or access to the details of all the `Task`s of a cluster.\n"}
{"id": 1205, "context": "## Context\nWe sought to determine whether to deliver our document management capabilities using the content management platform natively or through the integration of an external document management platform.\nWe sought to determine whether Bloomreach's 'Channel' concept would be suitable for managing the various sites required to be brought onto the platform both at MVP and in the future, such as Deenary and Speciality sights.\nAs part of this, considerations were made around:\n* Ease of use for creating new sites\n* Ability to share components\n* Ability to segregate content for specific channels (sites)\n* Ability to share content up and down the stack where needed and appropriate\n* Permissions model required to support this model\n"}
{"id": 3907, "context": "## Context\nOur service-operator allows service teams to provision various AWS services by\ndeclaratively defining resources and submitting them via the kubernetes api.\nSome of these resources require IAM to authorise how the provisioned service\ncan be used. The types of actions that can be performed on.\n#### Example\nThe service operator allows provisioning of S3 buckets and bucket configuration such as:\n```\n---\napiVersion: storage.govsvc.uk/v1beta1\nkind: S3Bucket\nmetadata:\nname: s3-bucket-sample\nspec:\naws:\nLifecycleRules:\n- Expiration: 90days\nVersioning:\nEnabled: true\n```\nIn order to access a provisioned bucket via the the AWS SDK users will require\nan IAM role/policy that allows access.\nWe want things like bucket ACL, versioning configuration and lifecycle policy\nto be defined declaratively via the resource manifest (see example above), and continuously managed\nby the service operator.\nWe want users of the provisioned bucket to be able to read back all\nconfiguration, and be able to fully utilise the specific bucket for reading,\nwriting and managing their objects within the provisioned bucket, but we want\nto avoid giving permissions to users that could cause conflicts with the\nproperties that are managed by the service operator's reconcile loop.\nFor example, given the example manifest above, we would like to avoid giving\npermissions that would allow a user to alter the Expiration LifeCycleRules,\nsince any changes the user made would be periodically overwritten by the\nservice operator's reconciliation.\n"}
{"id": 2816, "context": "## Context\nWe want to avoid testing implementation details in our integration tests.\nWe want to use `react-testing-library` which makes it easier to make assertions on the rendered DOM rather than assert implementation details. But mostly because it enable us to find and trigger click events on different UI elements.\ne.g. toggling the visibility of different tabs and window groups.\nBut when it comes to asserting the rendered DOM, in most cases we trust the view will render the model properly.\nIt could be more sensible to only verify the state/model.\n"}
{"id": 3987, "context": "## Context\nThere are a number of ways an API could allow clients to upload files to S3, the popular ones:\n- Allow the API to accept Base 64 encoded files in a JSON POST request and subsequently send this blob to S3\n- Allow the API to accept multipart form uploads, compile the parts on the server then send the file to S3\n- Use the S3 Presigned URL functionality, which allows the client to act as the IAM which created the URL for a single operation, and upload the file directly to S3 themselves\n"}
