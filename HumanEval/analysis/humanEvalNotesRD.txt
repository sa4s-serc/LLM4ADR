In many of the reviews, its clear that the Approach generates small Design Decision with respect to prompting and RAG, with Gemini and GPT respectively. And the reviewers don't like that. This brevity has received mixed feedback. Most reviewers express dissatisfaction with these short responses, stating that the outputs lack depth and elaboration. Reviewers mostly like bigger and elaborative responses.
Multiple cases the users have made comments like 'Could get into more detailing?' or 'Could have been more elaborate' on the Decisions generated by Approach.

However some users presented a short context and wished for a short a simple response. For example one user gave the context 'I want to reduce latency during message fetch'. Here RAG with GPT gave a 148 word answer: 'Implement a caching layer to improve the latency... repetitive calls to the primary datastore'. the user commented: 'Gives a very detailed response perhaps required in the next stage. Maybe compress this in a one liner stating type of cache required with the appropriate reason'. Whereas the approach with Gemma returned: 'I will use a local cache to store messages.', where the user commented: 'Gives a simple logical answer to the context'.

We have seen a lot of the data in the training set which have very small ADR. This might be a reason why our approach learnt to generate small ADRs. We are giving a statistical reasoning for that.

The Approach is optimised for generating Decision from Contexts in a structured manner (C â†’ D). It is not designed as an instruction-tuned model, which are typically required to act as a conversational co-pilot and follow user instructions and reply to user query. However some people tried to use it as a co-pilot. For example one person asked 'How can multiple cyber security products integrate to provide a view on "Job to be Done" for different personas' and 'How should agent based cyber security products be developed?' which are not 'context' but query. --> this might be influenced by mental model of using GPT kind of services, where user ask query.

There is also some cases, where Flan-T5 just hallucinates. This suggests too small or too older models might come up with this kind of issues. We can also observe some hallucination during testing.