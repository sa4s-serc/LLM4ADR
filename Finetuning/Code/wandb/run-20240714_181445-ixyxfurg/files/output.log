
  0%|                                                                                                                                                                | 0/1480 [00:00<?, ?it/s]/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '


  1%|█                                                                                                                                                      | 10/1480 [00:13<14:44,  1.66it/s]
{'loss': 26.8969, 'grad_norm': 250.37596130371094, 'learning_rate': 4.9662162162162164e-05, 'epoch': 0.14}
 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:00<00:00,  2.13it/s]


  1%|█▉                                                                                                                                                     | 19/1480 [00:21<13:47,  1.77it/s]
  1%|██                                                                                                                                                     | 20/1480 [00:22<13:15,  1.83it/s]

  0%|                                                                                                                                                                   | 0/4 [00:00<?, ?it/s]


  2%|██▊                                                                                                                                                    | 28/1480 [00:29<14:21,  1.69it/s]
  2%|███                                                                                                                                                    | 30/1480 [00:30<13:11,  1.83it/s]

 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 3/4 [00:02<00:00,  1.40it/s]



  3%|████                                                                                                                                                   | 40/1480 [00:39<14:58,  1.60it/s]
{'loss': 8.2357, 'grad_norm': 41.19426727294922, 'learning_rate': 4.8648648648648654e-05, 'epoch': 0.54}
 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:01<00:01,  1.96it/s]



  3%|████▉                                                                                                                                                  | 49/1480 [00:47<15:49,  1.51it/s]
  3%|█████                                                                                                                                                  | 50/1480 [00:48<14:38,  1.63it/s]

  0%|                                                                                                                                                                   | 0/4 [00:00<?, ?it/s]


  4%|█████▉                                                                                                                                                 | 58/1480 [00:55<16:09,  1.47it/s]
  4%|██████                                                                                                                                                 | 60/1480 [00:56<13:55,  1.70it/s]

 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 3/4 [00:02<00:00,  1.39it/s]



  5%|███████▏                                                                                                                                               | 70/1480 [01:05<13:26,  1.75it/s]
{'loss': 3.8791, 'grad_norm': 12.047733306884766, 'learning_rate': 4.763513513513514e-05, 'epoch': 0.95}
 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:01<00:01,  1.96it/s]



  5%|████████▏                                                                                                                                              | 80/1480 [01:14<13:20,  1.75it/s]
{'loss': 3.4109, 'grad_norm': 16.88435173034668, 'learning_rate': 4.72972972972973e-05, 'epoch': 1.08}

 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:01<00:01,  1.96it/s]


  6%|█████████                                                                                                                                              | 89/1480 [01:22<13:30,  1.72it/s]
  6%|█████████▏                                                                                                                                             | 90/1480 [01:22<12:54,  1.79it/s]

  0%|                                                                                                                                                                   | 0/4 [00:00<?, ?it/s]


  7%|██████████▏                                                                                                                                           | 100/1480 [01:31<12:49,  1.79it/s]
  0%|                                                                                                                                                                   | 0/4 [00:00<?, ?it/s]

 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 3/4 [00:02<00:00,  1.39it/s]



  7%|███████████▏                                                                                                                                          | 110/1480 [01:39<12:33,  1.82it/s]
{'loss': 1.7287, 'grad_norm': 10.349754333496094, 'learning_rate': 4.628378378378378e-05, 'epoch': 1.49}
 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:01<00:01,  1.95it/s]



  8%|████████████▏                                                                                                                                         | 120/1480 [01:48<12:27,  1.82it/s]
{'loss': 1.4844, 'grad_norm': 4.575988292694092, 'learning_rate': 4.594594594594595e-05, 'epoch': 1.62}

 50%|█████████████████████████████████████████████████████████████████████████████▌                                                                             | 2/4 [00:01<00:01,  1.95it/s]

  8%|████████████▋                                                                                                                                         | 125/1480 [01:54<17:24,  1.30it/s]Traceback (most recent call last):
  File "/home2/adyansh/LLM4ADR/Finetuning/Code/local-script.py", line 147, in <module>
    training_data = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 1859, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 2203, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/transformers/trainer.py", line 3147, in training_step
    self.accelerator.backward(loss)
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/accelerate/accelerator.py", line 2013, in backward
    loss.backward(**kwargs)
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home2/adyansh/LLM4ADR/research/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt